{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8675378,"sourceType":"datasetVersion","datasetId":5198946}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false},"colab":{"provenance":[]}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Imports","metadata":{"id":"4chTrP_CUG-o"}},{"cell_type":"code","source":"# !pip show ipywidgets\n!jupyter nbextension enable --py widgetsnbextension\n# !pip install ipympl","metadata":{"id":"Vd1nFpuiUG-p","outputId":"6fbe764d-f6f4-46eb-f6e0-01be2dd24b6f","execution":{"iopub.status.busy":"2024-06-15T09:05:09.450369Z","iopub.execute_input":"2024-06-15T09:05:09.451145Z","iopub.status.idle":"2024-06-15T09:05:10.956983Z","shell.execute_reply.started":"2024-06-15T09:05:09.451106Z","shell.execute_reply":"2024-06-15T09:05:10.955392Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nimport cv2\n# from google.colab.patches import cv2_imshow\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nimport keras","metadata":{"id":"G4XxnAkNUG-r","execution":{"iopub.status.busy":"2024-06-15T08:49:58.68292Z","iopub.execute_input":"2024-06-15T08:49:58.683406Z","iopub.status.idle":"2024-06-15T08:50:03.668445Z","shell.execute_reply.started":"2024-06-15T08:49:58.683364Z","shell.execute_reply":"2024-06-15T08:50:03.666918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data","metadata":{"id":"qZ5bFJdLUuri"}},{"cell_type":"markdown","source":"## Initializing Environment in Kaggle","metadata":{"id":"3-yzyCieUOQK"}},{"cell_type":"code","source":"dataset_dir = '/kaggle/working'","metadata":{"id":"QwFDWSRFUG-t","execution":{"iopub.status.busy":"2024-06-15T08:50:03.670796Z","iopub.execute_input":"2024-06-15T08:50:03.671499Z","iopub.status.idle":"2024-06-15T08:50:03.676892Z","shell.execute_reply.started":"2024-06-15T08:50:03.671464Z","shell.execute_reply":"2024-06-15T08:50:03.675626Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport json\n\nfrom kaggle_secrets import UserSecretsClient\nsecrets = UserSecretsClient()\n\nos.environ['KAGGLE_USERNAME'] = secrets.get_secret(\"KAGGLE_USERNAME\")\nos.environ['KAGGLE_KEY'] = secrets.get_secret(\"KAGGLE_KEY\")","metadata":{"id":"QJfOXHGOUG-t","outputId":"1bd2a9ad-3b82-45e6-aa85-d548c51b081a","execution":{"iopub.status.busy":"2024-06-15T08:50:03.678372Z","iopub.execute_input":"2024-06-15T08:50:03.67876Z","iopub.status.idle":"2024-06-15T08:50:04.222146Z","shell.execute_reply.started":"2024-06-15T08:50:03.678718Z","shell.execute_reply":"2024-06-15T08:50:04.221099Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# meta = dict(\n#     id=\"ishansrivastava1308/Cloud-Images-19510\",\n#     title=\"Cloud images Dataset\",\n#     isPrivate=True,\n#     licenses=[dict(name=\"other\")]\n# )\n\n# with open(os.path.join('dataset-metadata.json'), 'w') as f:\n#     json.dump(meta, f)\n","metadata":{"id":"4Ei616lWUG-t","execution":{"iopub.status.busy":"2024-06-15T08:50:04.22436Z","iopub.execute_input":"2024-06-15T08:50:04.224707Z","iopub.status.idle":"2024-06-15T08:50:04.230483Z","shell.execute_reply.started":"2024-06-15T08:50:04.224679Z","shell.execute_reply":"2024-06-15T08:50:04.228875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !kaggle datasets init","metadata":{"id":"Tf_TMO2fUG-u","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !kaggle datasets create -p {dataset_dir} --dir-mode zip","metadata":{"id":"kWUPP5YTUG-u","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Initializing Environment in Google Colab","metadata":{"id":"ItUpZCikUUHE"}},{"cell_type":"code","source":"import os\nimport json\n\nfrom google.colab import userdata\n\nos.environ['KAGGLE_USERNAME'] = userdata.get(\"KAGGLE_USERNAME\")\nos.environ['KAGGLE_KEY'] = userdata.get(\"KAGGLE_KEY\")","metadata":{"id":"m7iIFRDCUeSD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Downloading Data in google colab","metadata":{"id":"cIPi92D7U3j-"}},{"cell_type":"code","source":"!kaggle datasets download ishansrivastava1308/cloud-images-19510 -p /content/kaggle/input --force\n!unzip /content/kaggle/input/cloud-images-19510.zip -d /content/kaggle/input/cloud-images-19510 && rm /content/kaggle/input/cloud-images-19510.zip\n","metadata":{"id":"CQibnXcAU6IT","outputId":"bbf63291-3aff-4146-a000-02cff8e31cbc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rm -r kaggle/input/","metadata":{"id":"YkrFXmW5Zcgx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Undistorting Images","metadata":{"id":"P31E4vlJUG-u"}},{"cell_type":"code","source":"PWD = os.getcwd()\nprint(PWD)","metadata":{"id":"7YqGZ4EQX9lZ","execution":{"iopub.status.busy":"2024-06-15T08:50:17.203793Z","iopub.execute_input":"2024-06-15T08:50:17.204242Z","iopub.status.idle":"2024-06-15T08:50:17.212569Z","shell.execute_reply.started":"2024-06-15T08:50:17.204207Z","shell.execute_reply":"2024-06-15T08:50:17.211098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img = tf.keras.utils.load_img(os.path.join(PWD,'kaggle/input/cloud-images-19510/0101/0101075000.jpg'), target_size = (800,800))\nimg","metadata":{"id":"EylbeWyfUG-v","outputId":"25637f2e-422b-4f7b-8b00-43ebea361e17","execution":{"iopub.status.busy":"2024-06-15T08:59:01.855778Z","iopub.execute_input":"2024-06-15T08:59:01.856261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dist = 0.4; f = 400;\ndim = 2048\nDIM=(dim, dim)\nK=np.array([\n    [f, 0.0, 1536/2],\n    [0.0, f, 1536/2],\n    [0.0, 0.0, 1.0]])\nD=np.array([[dist],[dist],[dist],[dist]])\n\n\ndef undistort(img_path = None,zoom_out_factor = 1, balance=0.0, dim2=None, dim3=None,*args, **kwargs):\n    img = cv2.imread(img_path)\n\n    dim1 = img.shape[:2][::-1]  #dim1 is the dimension of input image to un-distort\n    assert dim1[0]/dim1[1] == DIM[0]/DIM[1], \"Image to undistort needs to have same aspect ratio as the ones used in calibration\"\n    if not dim2:\n        dim2 = dim1\n    if not dim3:\n        dim3 = dim1\n    scaled_K = K.copy()\n#     scaled_K[0][0] /= zoom_out_factor\n#     scaled_K[1][1] /= zoom_out_factor\n#     scaled_K[2][2] = 1.0  # Except that K[2][2] is always 1.0\n    # This is how scaled_K, dim2 and balance are used to determine the final K used to un-distort image. OpenCV document failed to make this clear!\n#     new_K = cv2.fisheye.estimateNewCameraMatrixForUndistortRectify(scaled_K, D, dim2, , balance=balance)\n    new_K = K.copy()\n    new_K[0][0] /= zoom_out_factor\n    new_K[1][1] /= zoom_out_factor\n    map1, map2 = cv2.fisheye.initUndistortRectifyMap(scaled_K, D, np.eye(3), new_K, dim3, cv2.CV_16SC2)\n    undistorted_img = cv2.remap(img, map1, map2, interpolation=cv2.INTER_AREA, borderMode=cv2.BORDER_CONSTANT)\n    undistorted_img = cv2.cvtColor(undistorted_img, cv2.COLOR_BGR2RGB)\n    undistorted_img = cv2.resize(undistorted_img, (1000,1000))\n    return undistorted_img\n\n\n\n\n","metadata":{"id":"W821fmXTUG-v","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nimport IPython\nfrom IPython.display import display\nfrom ipywidgets import interact, IntSlider, fixed, FloatSlider, IntRangeSlider\n\n@interact(img=fixed(img), dist = (0.,1.,0.001), f = (1,1000,1), zoom_out_factor = (1,200,1),balance = (0.,1.,0.1))\ndef undistorted_wrap(img_path,dist = 0.025, f = 400 ,zoom_out_factor = 2, balance=1.0,*args, **kwargs):\n    dim = 2048\n    DIM=(dim, dim)\n#     img = cv2.imread(img_path)\n    \n    K=np.array([\n        [f, 0.0, 1536/2],\n        [0.0, f, 1536/2],\n        [0.0, 0.0, 1.0]])\n    D=np.array([[dist],[dist],[dist],[dist]])\n\n\n    dim1 = img.shape[:2][::-1]  #dim1 is the dimension of input image to un-distort\n    new_K = np.array([\n        [f / zoom_out_factor, 0.0, 1536/2],\n        [0.0, f /zoom_out_factor, 1536/2],\n        [0.0, 0.0, 1.0]])\n    map1, map2 = cv2.fisheye.initUndistortRectifyMap(K, D, np.eye(3), new_K, dim1, cv2.CV_16SC2)\n    undistorted_img = cv2.remap(img, map1, map2, interpolation=cv2.INTER_AREA, borderMode=cv2.BORDER_CONSTANT)\n    undistorted_img = cv2.cvtColor(undistorted_img, cv2.COLOR_BGR2RGB)\n    undistorted_img = cv2.resize(undistorted_img, (1000,1000))\n    plt.figure(figsize=(5,5))\n    plt.axis('off')\n    plt.imshow(undistorted_img)\n","metadata":{"id":"wowrR6D3UG-w","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nimg = cv2.imread(os.path.join(PWD,'kaggle/input/cloud-images-19510/0101/0101075000.jpg'))\n\nimport IPython\nfrom IPython.display import display\nfrom ipywidgets import interact, IntSlider, fixed, FloatSlider, IntRangeSlider, interactive\n\ndef undistorted_wrap_with_coeffs(img, f = 400 ,zoom_out_factor = 2, balance=1.0, k1 = 0.025, k2 = 0.025, k3 =0.025, k4 = 0.025,*args, **kwargs):\n    dim = 2048\n    DIM=(dim, dim)\n#     img = cv2.imread(img_path)\n    K=np.array([\n        [f, 0.0, 1536/2],\n        [0.0, f, 1536/2],\n        [0.0, 0.0, 1.0]])\n    D=np.array([[k1],[k2],[k3],[k4]])\n\n    dim1 = img.shape[:2][::-1]  #dim1 is the dimension of input image to un-distort\n    new_K = np.array([\n        [f / zoom_out_factor, 0.0, 1536/2],\n        [0.0, f /zoom_out_factor, 1536/2],\n        [0.0, 0.0, 1.0]])\n    map1, map2 = cv2.fisheye.initUndistortRectifyMap(K, D, np.eye(3), new_K, dim1, cv2.CV_16SC2)\n    undistorted_img = cv2.remap(img, map1, map2, interpolation=cv2.INTER_AREA, borderMode=cv2.BORDER_CONSTANT)\n    undistorted_img = cv2.cvtColor(undistorted_img, cv2.COLOR_BGR2RGB)\n    undistorted_img = cv2.resize(undistorted_img, (1000,1000))\n    plt.figure(figsize=(5,5))\n    plt.axis('off')\n    \ndistort_widget = interactive(\n    undistorted_wrap_with_coeffs,\n    img=fixed(img), \n    f = (1,1000,1), \n    zoom_out_factor = (1,200,1),\n    balance = (0.,1.,0.1), \n    k1 = (0.,1.,0.001),\n    k2 = (0.,1.,0.001),\n    k3 = (0.,1.,0.001),\n    k4 = (0.,1.,0.001),\n    \n)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-06-15T09:05:24.707674Z","iopub.execute_input":"2024-06-15T09:05:24.708712Z","iopub.status.idle":"2024-06-15T09:05:25.224003Z","shell.execute_reply.started":"2024-06-15T09:05:24.708669Z","shell.execute_reply":"2024-06-15T09:05:25.221348Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import display\ndisplay(distort_widget)","metadata":{"id":"EHp3PjO-UG-x","outputId":"83b6b836-d059-4150-efe6-ac955e547bab","execution":{"iopub.status.busy":"2024-06-15T09:05:28.345737Z","iopub.execute_input":"2024-06-15T09:05:28.346173Z","iopub.status.idle":"2024-06-15T09:05:28.540444Z","shell.execute_reply.started":"2024-06-15T09:05:28.34614Z","shell.execute_reply":"2024-06-15T09:05:28.539334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"undistorted_widget_wrap(img_path = '/kaggle/input/cloud-images-19510/0105/0105112000.jpg')(dist = 0.025,f = 600,zoom_out_factor = 1,balance = 1)","metadata":{"id":"gUtxQeTSUG-x","outputId":"35568119-dcb8-43b9-dc0e-0a82877d21f8","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%matplotlib inline","metadata":{"id":"lfCWwYFfUG-x","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"DNsxyN51UG-y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import IPython\nfrom IPython.display import display\nfrom ipywidgets import interact, IntSlider, fixed, FloatSlider, IntRangeSlider\nbalance = FloatSlider(min=0, max=1, value=1, description='Balance:')\ndisplay(interact(\n    undistorted_widget_wrap,\n    img = fixed('/kaggle/input/cloud-images-19510/0105/0105120000.jpg'),\n    dist = FloatSlider(min = 0, max = 1, step = 0.00001, value = 0.01),\n    f = IntSlider(min = 1, max = 1000, step = 1, value = 400),\n    zoom_out_factor=FloatSlider(min=0, max=20, step=0.01, value=5),\n    balance = balance,\n\n))\n\n#","metadata":{"id":"naZWuHSeUG-y","outputId":"add8fd44-0f9d-461b-dcb3-5b487f5d4b95","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!jupyter nbextension enable --py --sys-prefix widgetsnbextension","metadata":{"id":"SE3DNkRQUG-y","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"oSZlufy7UG-y","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%matplotlib notebook\nimport ipywidgets as widgets\n\n# For explicitly displaying widgets\nfrom IPython.display import display\n\n# Just need these for the demo purposes here\nfrom datetime import datetime\nimport matplotlib.pyplot as plt\ndemo_IntSlider_1 = widgets.IntSlider(\n    min=1,                      # The minimum value\n    max=100,                    # The maximum value\n    description='Int Slider 1', # Label\n    value=53,                   # Default value\n)\n\n# Display the widget\ndisplay(demo_IntSlider_1)","metadata":{"id":"giUokFRzUG-y","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"u_img = undistort('/kaggle/input/cloud-images-19510/0105/0105112000.jpg',zoom_out_factor = 100,balance = 1)\ntf.keras.utils.array_to_img(u_img)","metadata":{"id":"ARGt-aKRUG-z","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"WWPWIVljUG-z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfig,ax = plt.subplots(nrows = 3, ncols = 3)\naxes = ax.flatten()\nfor a in axes:\n    a.imshow()","metadata":{"id":"_vSZxmH0UG-z","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.keras.utils.array_to_img(map1)","metadata":{"id":"hWdnUSajUG-z","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.keras.utils.array_to_img(undistort('/kaggle/input/cloud-images-19510/0101/0101075000.jpg',balance = 1), )","metadata":{"id":"xFu-eENUUG-1","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(img)","metadata":{"id":"ZS0HZ5c6UG-2","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img","metadata":{"id":"RDH7zV6rUG-2","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"8CYbHmhDUG-2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{"id":"1iUCI0OSUxet"}},{"cell_type":"markdown","source":"# Data Preprocessing","metadata":{"id":"0X_kQq4tUG-2"}},{"cell_type":"markdown","source":"## Creating Tensorflow Datsets","metadata":{"id":"MkbjVLpgUG-3"}},{"cell_type":"code","source":"base_path = '/kaggle/input/cloud-images-19510'","metadata":{"id":"4ba4FBBWUG-3","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_paths = [sorted([os.path.join(root,file) for file in files if file.endswith('.jpg')]) for root,dirs,files in os.walk(base_path) if len(dirs) == 0]","metadata":{"id":"CU_twV5uUG-3","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"flattened_image_paths = sorted([os.path.join(root,file) for root,dirs,files in os.walk(base_path) for file in files if not file.endswith('.csv')])","metadata":{"id":"5A8oWUGkUG-3","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def undistort_from_array(img, dim2 = None, dim3 = None, balance = 0):\n    dim1 = img.shape[:2][::-1]  #dim1 is the dimension of input image to un-distort\n    assert dim1[0]/dim1[1] == DIM[0]/DIM[1], \"Image to undistort needs to have same aspect ratio as the ones used in calibration\"\n    if not dim2:\n        dim2 = dim1\n    if not dim3:\n        dim3 = dim1\n    scaled_K = K * dim1[0] / DIM[0]  # The values of K is to scale with image dimension.\n    scaled_K[2][2] = 1.0  # Except that K[2][2] is always 1.0\n    # This is how scaled_K, dim2 and balance are used to determine the final K used to un-distort image. OpenCV document failed to make this clear!\n    new_K = cv2.fisheye.estimateNewCameraMatrixForUndistortRectify(scaled_K, D, dim2, np.eye(3), balance=balance)\n    map1, map2 = cv2.fisheye.initUndistortRectifyMap(scaled_K, D, np.eye(3), new_K, dim3, cv2.CV_16SC2)\n    undistorted_img = cv2.remap(img, map1, map2, interpolation=cv2.INTER_LINEAR, borderMode=cv2.BORDER_CONSTANT)\n    undistorted_img = cv2.cvtColor(undistorted_img, cv2.COLOR_BGR2RGB)\n    undistorted_img = cv2.resize(undistorted_img, (1000,1000))\n    return undistorted_img\n","metadata":{"id":"tEcwHObzUG-3","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\n\nclass Preprocessor:\n    def __init__(\n            self,\n            filepaths : list[str]\n    ):\n        self.filepaths = filepaths\n        self.dataset = None\n\n    def get_dataset_iterator(self,func):\n        if self.dataset:\n            return self.dataset\n        self.dataset = tf.data.Dataset.from_tensor_slices(self.filepaths)\n        self.dataset = self.dataset.map(func, num_parallel_calls=tf.data.AUTOTUNE)\n        # self.dataset = self.dataset.cache()\n        # self.dataset = self.dataset.shuffle(buffer_size=1000)\n        # self.dataset = self.dataset.batch(32)\n        # self.dataset = self.dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n        return self.dataset\n@tf.function\ndef load_preprocess_y(file_path):\n    image = tf.io.read_file(file_path)\n    image = tf.image.decode_jpeg(image, channels=1)\n    image = tf.image.resize(image, [128, 256], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n    return image\n\n@tf.function\ndef get_image_from_path(file_path):\n    return image\n\n@tf.py_function(Tout=tf.float64)\ndef get_undistorted_img(file_path):\n    path_str = file_path.numpy().decode('utf-8')\n    image = undistort(path_str,zoom_out_factor = 10,balance = 1)\n    return tf.convert_to_tensor(image,dtype = tf.float64)","metadata":{"id":"J7t6H-P2UG-4","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_ds_x = Preprocessor(flattened_image_paths).get_dataset_iterator(get_undistorted_img)\n# train_ds_x.map(get_undistorted_img)","metadata":{"id":"ZObMVoLUUG-4","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_iter = train_ds_x.as_numpy_iterator()","metadata":{"id":"6Lnv3hq6UG_G","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def show_grid_samples(ncols = 3,nrows = 3,scale = 1,**kwargs):\n    figsize = (ncols * scale, nrows * scale)\n    plt.tight_layout()\n    fig,ax = plt.subplots(ncols = ncols, nrows = nrows, figsize = figsize)\n    axes = ax.flatten()\n    for a in axes:\n        a.imshow(image_iter.next()/255, interpolation = 'nearest')\n        a.axis('off')\n    plt.subplots_adjust(wspace=0, hspace=0)\n\n    plt.show()","metadata":{"id":"RcCKlXEAUG_G","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%matplotlib notebook","metadata":{"id":"xiRszRhIUG_G","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_grid_samples(ncols = 3,nrows = 10,scale = 5)","metadata":{"id":"7l98cFZ3UG_H","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"Sqr4A2tVUG_H"},"execution_count":null,"outputs":[]}]}