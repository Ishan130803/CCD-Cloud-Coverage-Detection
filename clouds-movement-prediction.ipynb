{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"tpu1vmV38","dataSources":[{"sourceId":2725333,"sourceType":"datasetVersion","datasetId":1661127},{"sourceId":8765259,"sourceType":"datasetVersion","datasetId":5198946},{"sourceId":67520,"sourceType":"modelInstanceVersion","modelInstanceId":56052},{"sourceId":68476,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":57091}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false},"colab":{"provenance":[{"file_id":"https://github.com/Ishan130803/CCD-Cloud-Coverage-Detection/blob/main/clouds-movement-prediction.ipynb","timestamp":1718543090351}]}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Installation","metadata":{"id":"Qd0G6ebiIxue"}},{"cell_type":"code","source":"!pip install ipywidgets\n!jupyter nbextension enable --py widgetsnbextension\n!pip install ipympl","metadata":{"id":"Vd1nFpuiUG-p","scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Imports","metadata":{"id":"4chTrP_CUG-o"}},{"cell_type":"code","source":"import tensorflow as tf\nimport cv2\n# from google.colab.patches import cv2_imshow\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nimport keras\nimport pandas as pd\nfrom pprint import pprint\nfrom collections import defaultdict\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nimport joblib\n","metadata":{"id":"G4XxnAkNUG-r","outputId":"c31cac35-6ba4-483b-d460-259fb7bfa6cf","execution":{"iopub.status.busy":"2024-06-23T16:22:39.950308Z","iopub.execute_input":"2024-06-23T16:22:39.950633Z","iopub.status.idle":"2024-06-23T16:22:53.064043Z","shell.execute_reply.started":"2024-06-23T16:22:39.950606Z","shell.execute_reply":"2024-06-23T16:22:53.063241Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"2024-06-23 16:22:41.715926: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-06-23 16:22:41.716011: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-06-23 16:22:41.846526: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# TPU setup","metadata":{}},{"cell_type":"code","source":"import math, re, os\nimport tensorflow as tf\nimport numpy as np\nfrom matplotlib import pyplot as plt\nfrom kaggle_datasets import KaggleDatasets\nfrom sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\nprint(\"Tensorflow version \" + tf.__version__)\nAUTO = tf.data.experimental.AUTOTUNE\n\n# Detect TPU, return appropriate distribution strategy\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver() \n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    strategy = tf.distribute.get_strategy() \n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data","metadata":{"id":"qZ5bFJdLUuri"}},{"cell_type":"markdown","source":"## Initializing Environment in Kaggle","metadata":{"id":"3-yzyCieUOQK"}},{"cell_type":"code","source":"dataset_dir = '/kaggle/working'","metadata":{"id":"QwFDWSRFUG-t","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!cp -r /kaggle/input/cloud-images-19510/ /kaggle/working/","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!cp -r /kaggle/input/cloud-images-19510/ /kaggle/working/","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport json\n\nfrom kaggle_secrets import UserSecretsClient\nsecrets = UserSecretsClient()\n\nos.environ['KAGGLE_USERNAME'] = secrets.get_secret(\"KAGGLE_USERNAME\")\nos.environ['KAGGLE_KEY'] = secrets.get_secret(\"KAGGLE_KEY\")\n\n!cp -r /kaggle/input/cloud-images-19510/ /kaggle/working/\n\nmeta = dict(\n    id=\"ishansrivastava1308/Cloud-Images-19510\",\n    title=\"Cloud images Dataset\",\n    isPrivate=False,\n    licenses=[dict(name=\"other\")]\n)\n\nwith open(os.path.join('/kaggle/working/cloud-images-19510','dataset-metadata.json'), 'w') as f:\n    json.dump(meta, f)\n    \n\n!kaggle datasets version -m \"Version 7 Classified Update\" -p /kaggle/working/cloud-images-19510 --dir-mode tar","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!cp -r /kaggle/input/cloud-images-19510/cloud-images-19510/train.csv /kaggle/working/","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.path.join('/kaggle/working/cloud-images-19510','dataset-metadata.json')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport json\n\nfrom kaggle_secrets import UserSecretsClient\nsecrets = UserSecretsClient()\n\nos.environ['KAGGLE_USERNAME'] = secrets.get_secret(\"KAGGLE_USERNAME\")\nos.environ['KAGGLE_KEY'] = secrets.get_secret(\"KAGGLE_KEY\")","metadata":{"id":"QJfOXHGOUG-t","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\n\nmeta = dict(\n    id=\"ishansrivastava1308/Cloud-Images-19510\",\n    title=\"Cloud images Dataset\",\n    isPrivate=False,\n    licenses=[dict(name=\"other\")]\n)\n\nwith open(os.path.join('/kaggle/working/cloud-images-19510','dataset-metadata.json'), 'w') as f:\n    json.dump(meta, f)\n","metadata":{"id":"4Ei616lWUG-t","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !kaggle datasets init","metadata":{"id":"Tf_TMO2fUG-u","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !kaggle datasets create -p {dataset_dir} --dir-mode zip","metadata":{"id":"kWUPP5YTUG-u","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!kaggle datasets version -m \"Version 4  Update\" -p /kaggle/working/ --dir-mode tar -d","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Creating new Dataset Version","metadata":{}},{"cell_type":"markdown","source":"## Initializing Environment in Google Colab","metadata":{"id":"ItUpZCikUUHE"}},{"cell_type":"code","source":"import os\nimport json\n\nfrom google.colab import userdata\n\nos.environ['KAGGLE_USERNAME'] = userdata.get(\"KAGGLE_USERNAME\")\nos.environ['KAGGLE_KEY'] = userdata.get(\"KAGGLE_KEY\")","metadata":{"id":"m7iIFRDCUeSD","outputId":"0dbabd29-8577-4e55-9add-3df54d63669e","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Downloading Data in google colab","metadata":{"id":"cIPi92D7U3j-"}},{"cell_type":"code","source":"!kaggle datasets download ishansrivastava1308/cloud-images-19510 -p /content/kaggle/input --force\n!unzip /content/kaggle/input/cloud-images-19510.zip -d /content/kaggle/input/cloud-images-19510 && rm /content/kaggle/input/cloud-images-19510.zip\n","metadata":{"id":"CQibnXcAU6IT","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# rm -r kaggle/input/","metadata":{"id":"YkrFXmW5Zcgx","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Undistorting Images","metadata":{"id":"P31E4vlJUG-u"}},{"cell_type":"code","source":"PWD = os.getcwd()\nprint(PWD)","metadata":{"id":"7YqGZ4EQX9lZ","outputId":"cc997134-fb53-4787-dd49-6328464e59ad","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img = tf.keras.utils.load_img(os.path.join(PWD,'kaggle/input/cloud-images-19510/0101/0101075000.jpg'), target_size = (800,800))\nimg","metadata":{"id":"EylbeWyfUG-v","outputId":"25637f2e-422b-4f7b-8b00-43ebea361e17","colab":{"base_uri":"https://localhost:8080/","height":280},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def undistort(img_path, zoom_out_factor, balance, f, dist):\n    dim = 2048\n    DIM=(dim, dim)\n    img = cv2.imread(img_path)\n\n    K=np.array([\n        [f, 0.0, 1536/2],\n        [0.0, f, 1536/2],\n        [0.0, 0.0, 1.0]])\n    D=np.array([[dist],[dist],[dist],[dist]])\n\n\n    dim1 = img.shape[:2][::-1]  #dim1 is the dimension of input image to un-distort\n    new_K = np.array([\n        [f / zoom_out_factor, 0.0, 1536/2],\n        [0.0, f /zoom_out_factor, 1536/2],\n        [0.0, 0.0, 1.0]])\n    map1, map2 = cv2.fisheye.initUndistortRectifyMap(K, D, np.eye(3), new_K, dim1, cv2.CV_16SC2)\n    undistorted_img = cv2.remap(img, map1, map2, interpolation=cv2.INTER_AREA, borderMode=cv2.BORDER_CONSTANT)\n    undistorted_img = cv2.cvtColor(undistorted_img, cv2.COLOR_BGR2RGB)\n    return undistorted_img","metadata":{"id":"XWuEnuFqIxus","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def undistort_func(img_path, zoom_out_factor, balance, f, dist):\n    dim = 2048\n    DIM=(dim, dim)\n    img = cv2.imread(img_path)\n\n    K=np.array([\n        [f, 0.0, 1536/2],\n        [0.0, f, 1536/2],\n        [0.0, 0.0, 1.0]])\n    D=np.array([[dist],[dist],[dist],[dist]])\n\n\n    dim1 = img.shape[:2][::-1]  #dim1 is the dimension of input image to un-distort\n    new_K = np.array([\n        [f / zoom_out_factor, 0.0, 1536/2],\n        [0.0, f /zoom_out_factor, 1536/2],\n        [0.0, 0.0, 1.0]])\n    map1, map2 = cv2.fisheye.initUndistortRectifyMap(K, D, np.eye(3), new_K, dim1, cv2.CV_16SC2)\n    undistorted_img = cv2.remap(img, map1, map2, interpolation=cv2.INTER_AREA, borderMode=cv2.BORDER_CONSTANT)\n    undistorted_img = cv2.cvtColor(undistorted_img, cv2.COLOR_BGR2RGB)\n    undistorted_img = cv2.resize(undistorted_img, (1000,1000))\n    plt.figure(figsize=(5,5))\n    plt.axis('off')\n    plt.imshow(undistorted_img)","metadata":{"id":"f_FTm5m5Ixut","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"undistort_func(os.path.join(PWD,'kaggle/input/cloud-images-19510/0101/0101075000.jpg'),5,1,250,0.025)","metadata":{"id":"qv5V_DzyIxut","outputId":"83169739-ea29-4080-b955-dfb883757e6d","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nimport IPython\nfrom IPython.display import display\nfrom ipywidgets import interact, IntSlider, fixed, FloatSlider, IntRangeSlider\n\nimg = cv2.imread(os.path.join(PWD,'kaggle/input/cloud-images-19510/0101/0101075000.jpg'))\n\n@interact(\n    img=fixed(value = img),\n    dist = FloatSlider(description = 'Dist'.ljust(15) + ':',  min = 0.,max = 1.,step = 0.001, readout_format = '0.3f'),\n    f = (1,1000,1),\n    zoom_out_factor = (1,200,1),\n    balance = (0.,1.,0.1)\n)\ndef undistorted_wrap(img,dist = 0.025, f = 400 ,zoom_out_factor = 2, balance=1.0,*args, **kwargs):\n    dim = 2048\n    DIM=(dim, dim)\n#     img = cv2.imread(img_path)\n\n    K=np.array([\n        [f, 0.0, 1536/2],\n        [0.0, f, 1536/2],\n        [0.0, 0.0, 1.0]])\n    D=np.array([[dist],[dist],[dist],[dist]])\n\n    dim1 = img.shape[:2][::-1]  #dim1 is the dimension of input image to un-distort\n    new_K = np.array([\n        [f / zoom_out_factor, 0.0, 1536/2],\n        [0.0, f /zoom_out_factor, 1536/2],\n        [0.0, 0.0, 1.0]])\n    map1, map2 = cv2.fisheye.initUndistortRectifyMap(K, D, np.eye(3), new_K, dim1, cv2.CV_16SC2)\n    undistorted_img = cv2.remap(img, map1, map2, interpolation=cv2.INTER_AREA, borderMode=cv2.BORDER_CONSTANT)\n    undistorted_img = cv2.cvtColor(undistorted_img, cv2.COLOR_BGR2RGB)\n    undistorted_img = cv2.resize(undistorted_img, (1000,1000))\n    plt.figure(figsize=(5,5))\n    plt.axis('off')\n    plt.imshow(undistorted_img)\n","metadata":{"id":"wowrR6D3UG-w","outputId":"46e5c500-862f-4a92-e9c0-73968cd52be3","colab":{"referenced_widgets":["ca3781cba6ad4f119cd96e0289f8e854"]},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(img)","metadata":{"id":"8TVQsV3KIxuu","outputId":"af5d598b-a160-4446-da32-21a39c5fab1f","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# img = cv2.imread(os.path.join(PWD,'/kaggle/input/cloud-images-19510/0101/0101100000.jpg'))\nimage = cv2.imread(os.path.join(PWD,'kaggle/input/cloud-images-19510/0101/0101080000.jpg'))\n\nimport IPython\nfrom IPython.display import display\nfrom ipywidgets import interact, IntSlider, fixed, FloatSlider, IntRangeSlider, interactive,interactive_output, HBox, VBox, Box, Layout\n\ndef undistorted_wrap_with_coeffs(img, f = 400 ,zoom_out_factor = 2, balance=1.0, k1 = 0.025, k2 = 0.025, k3 =0.025, k4 = 0.025, figsize = 1):\n    dim = 2048\n    DIM=(dim, dim)\n#     img = cv2.imread(img_path)\n    K=np.array([\n        [f, 0.0, 1536/2],\n        [0.0, f, 1536/2],\n        [0.0, 0.0, 1.0]])\n    D=np.array([[k1],[k2],[k3],[k4]])\n\n    dim1 = img.shape[:2][::-1]  #dim1 is the dimension of input image to un-distort\n    new_K = np.array([\n        [f / zoom_out_factor, 0.0, 1536/2],\n        [0.0, f /zoom_out_factor, 1536/2],\n        [0.0, 0.0, 1.0]])\n    map1, map2 = cv2.fisheye.initUndistortRectifyMap(K, D, np.eye(3), new_K, dim1, cv2.CV_16SC2)\n    undistorted_img = cv2.remap(img, map1, map2, interpolation=cv2.INTER_AREA, borderMode=cv2.BORDER_CONSTANT)\n    undistorted_img = cv2.cvtColor(undistorted_img, cv2.COLOR_BGR2RGB)\n    undistorted_img = cv2.resize(undistorted_img, (1000,1000))\n    plt.figure(figsize=(figsize,figsize))\n    plt.axis('off')\n    plt.imshow(undistorted_img)\n\n\nimg                       = fixed(description = 'img'.ljust(15) + ':', value =  image)\nf                         = IntSlider(description = 'f'.ljust(15) + ':',  min = 1,max = 1000, step = 1, value = 250)\nzoom_out_factor           = IntSlider(description = 'zoom_out_factor'.ljust(15) + ':',  min = 1,max = 200,step = 1, value = 16)\nbalance                   = FloatSlider(description = 'balance'.ljust(15) + ':',  min = 0.,max = 1.,step = 0.1,value = 1)\nk1                        = FloatSlider(description = 'k1'.ljust(15) + ':',  min = 0.,max = 1.,step = 0.001, value = 0.025, readout_format = '0.3f')\nk2                        = FloatSlider(description = 'k2'.ljust(15) + ':',  min = 0.,max = 1.,step = 0.001, value = 0.025,readout_format = '0.3f')\nk3                        = FloatSlider(description = 'k3'.ljust(15) + ':',  min = 0.,max = 1.,step = 0.001, value = 0.025,readout_format = '0.3f')\nk4                        = FloatSlider(description = 'k4'.ljust(15) + ':',  min = 0.,max = 1.,step = 0.001, value = 0.025,readout_format = '0.3f')\nfigsize                   = IntSlider(description = 'figsize'.ljust(15) + ':',  min = 3, max = 15, step = 1, value = 9)\n\n\nargs = {\n    'img' : img ,\n    'f'  : f ,\n    'zoom_out_factor'  : zoom_out_factor ,\n    'balance'  : balance ,\n    'k1'  : k1 ,\n    'k2'  : k2 ,\n    'k3'  : k3 ,\n    'k4'  : k4 ,\n    'figsize' : figsize ,\n}\n\ndistort_widget = interactive_output(\n    undistorted_wrap_with_coeffs,\n    args\n)\n\n","metadata":{"id":"0rb4jhDvIxuv","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sliders = list(args.values())","metadata":{"id":"eKVHYIBFIxuv","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"HBox([VBox(children = sliders[1:]), distort_widget], layout = Layout(flex = 'flex-row'))","metadata":{"id":"hmwxmu1BIxuw","outputId":"0431a399-6fe5-4cdd-9366-30cf05fafeb6","colab":{"referenced_widgets":["e00eaa1ff2ac4fdba0dd5c5a4a4f4d71"]},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Preprocessing","metadata":{"id":"0X_kQq4tUG-2"}},{"cell_type":"markdown","source":"## Creating Tensorflow Datsets","metadata":{"id":"MkbjVLpgUG-3"}},{"cell_type":"code","source":"base_path = '/kaggle/input/cloud-images-19510'","metadata":{"id":"4ba4FBBWUG-3","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_paths = [sorted([os.path.join(root,file) for file in files if file.endswith('.jpg')]) for root,dirs,files in os.walk(base_path) if len(dirs) == 0]","metadata":{"id":"CU_twV5uUG-3","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"flattened_image_paths = sorted([os.path.join(root,file) for root,dirs,files in os.walk(base_path) for file in files if not file.endswith('.csv')])","metadata":{"id":"5A8oWUGkUG-3","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(flattened_image_paths)","metadata":{"id":"mRIrdqPEIxuy","outputId":"cba63602-49e5-4559-924f-4b20245d7731","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def undistort_from_array(img, dim2 = None, dim3 = None, balance = 0):\n    dim1 = img.shape[:2][::-1]  #dim1 is the dimension of input image to un-distort\n    assert dim1[0]/dim1[1] == DIM[0]/DIM[1], \"Image to undistort needs to have same aspect ratio as the ones used in calibration\"\n    if not dim2:\n        dim2 = dim1\n    if not dim3:\n        dim3 = dim1\n    scaled_K = K * dim1[0] / DIM[0]  # The values of K is to scale with image dimension.\n    scaled_K[2][2] = 1.0  # Except that K[2][2] is always 1.0\n    # This is how scaled_K, dim2 and balance are used to determine the final K used to un-distort image. OpenCV document failed to make this clear!\n    new_K = cv2.fisheye.estimateNewCameraMatrixForUndistortRectify(scaled_K, D, dim2, np.eye(3), balance=balance)\n    map1, map2 = cv2.fisheye.initUndistortRectifyMap(scaled_K, D, np.eye(3), new_K, dim3, cv2.CV_16SC2)\n    undistorted_img = cv2.remap(img, map1, map2, interpolation=cv2.INTER_LINEAR, borderMode=cv2.BORDER_CONSTANT)\n    undistorted_img = cv2.cvtColor(undistorted_img, cv2.COLOR_BGR2RGB)\n    undistorted_img = cv2.resize(undistorted_img, (1000,1000))\n    return undistorted_img\n","metadata":{"id":"tEcwHObzUG-3","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\n\nclass Preprocessor:\n    def __init__(\n            self,\n            filepaths : list[str]\n    ):\n        self.filepaths = filepaths\n        self.dataset = None\n\n    def get_dataset_iterator(self,func):\n        if self.dataset:\n            return self.dataset\n        self.dataset = tf.data.Dataset.from_tensor_slices(self.filepaths)\n        self.dataset = self.dataset.map(func, num_parallel_calls=tf.data.AUTOTUNE)\n        # self.dataset = self.dataset.cache()\n        # self.dataset = self.dataset.shuffle(buffer_size=1000)\n        # self.dataset = self.dataset.batch(32)\n        # self.dataset = self.dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n        return self.dataset\n@tf.function\ndef load_preprocess_y(file_path):\n    image = tf.io.read_file(file_path)\n    image = tf.image.decode_jpeg(image, channels=1)\n    image = tf.image.resize(image, [128, 256], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n    return image\n\n@tf.function\ndef get_image_from_path(file_path):\n    return image\n\n@tf.py_function(Tout=tf.float64)\ndef get_undistorted_img(file_path):\n    path_str = file_path.numpy().decode('utf-8')\n    image = undistort(path_str,zoom_out_factor = 11,f = 282, dist = 0.015,balance = 1)\n    return tf.convert_to_tensor(image,dtype = tf.float64)","metadata":{"id":"J7t6H-P2UG-4","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_ds_x = Preprocessor(flattened_image_paths).get_dataset_iterator(get_undistorted_img)\n# train_ds_x.map(get_undistorted_img)","metadata":{"id":"ZObMVoLUUG-4","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_iter = train_ds_x.as_numpy_iterator()","metadata":{"id":"6Lnv3hq6UG_G","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def show_grid_samples(ncols = 3,nrows = 3,scale = 1,**kwargs):\n    figsize = (ncols * scale, nrows * scale)\n    plt.tight_layout()\n    fig,ax = plt.subplots(ncols = ncols, nrows = nrows, figsize = figsize)\n    axes = ax.flatten()\n    for a in axes:\n        a.imshow(image_iter.next()/255, interpolation = 'nearest')\n        a.axis('off')\n    plt.subplots_adjust(wspace=0, hspace=0)\n\n    plt.show()","metadata":{"id":"RcCKlXEAUG_G","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_grid_samples(ncols = 1,nrows = 2,scale = 5)","metadata":{"id":"7l98cFZ3UG_H","outputId":"b04fe3f5-1c68-48e3-a507-0692bbbd3223","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Sequence Modelling","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/cloud-images-19510/train_shell_remake_imputed.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = df.dropna()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train = df[df['Total Cloud Cover [%]'] > 0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import OrdinalEncoder\ntime_encoder = OrdinalEncoder().fit(train[['MST']].to_numpy())\ntrain.loc[:,'MST'] = time_encoder.transform(train[['MST']].to_numpy()).reshape(-1)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"time_dict = dict(zip(time_encoder.categories_[0],range(0,1440)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"time_dict['00:00']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scalerx = StandardScaler()\nscalery = StandardScaler()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# scalerx = joblib.load('/kaggle/input/ccd-ai/keras/LSTM-series-B/5/scalerx.joblib')\n# scalery = joblib.load('/kaggle/input/ccd-ai/keras/LSTM-series-B/5/scalery.joblib')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"days = train.iloc[:,1].unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_x_df = train[\n    ['MST', 'Global CMP22 (vent/cor) [W/m^2]',\n       'Direct sNIP [W/m^2]', 'Azimuth Angle [degrees]',\n       'Tower Dry Bulb Temp [deg C]', 'Tower Wet Bulb Temp [deg C]',\n       'Tower Dew Point Temp [deg C]', 'Tower RH [%]',\n       'Peak Wind Speed @ 6ft [m/s]', 'Avg Wind Direction @ 6ft [deg from N]',\n       'Station Pressure [mBar]', 'Precipitation (Accumulated) [mm]',\n       'Snow Depth [cm]', 'Moisture', 'Albedo (CMP11)']\n].astype(np.float64)\ntrain_x_df.loc[:,:] = scalerx.fit_transform(train_x_df)\n\ntrain_y_df = train[['Total Cloud Cover [%]']].astype(np.float64)\n\ntrain_y_df.loc[:,:] = scalery.fit_transform(train_y_df)\n\ntrain_x_df.loc[:,['Total Cloud Cover [%]']] = train_y_df.loc[:,['Total Cloud Cover [%]']]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lagged_columns = pd.concat([\n    train_y_df['Total Cloud Cover [%]'].shift(-15), \n    train_y_df['Total Cloud Cover [%]'].shift(-25),\n    train_y_df['Total Cloud Cover [%]'].shift(-30)\n], axis = 1)\nlagged_columns.columns = ['15_min_future','25_min_future','30_min_future']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.histplot(train[(train['MST'] > 400) & (train['MST'] < 1080)]['Total Cloud Cover [%]'], bins = 100)","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Finding linear relation of cloud cover with other features\n\ndef make_plots(\n    df : pd.DataFrame,\n    target_feature : str,\n    feature_pool : list[str],\n    nrows, ncols, scale\n):\n    fig,ax = plt.subplots(nrows = nrows, ncols = ncols, figsize = (scale*ncols ,scale*nrows))\n    ax = ax.flatten()\n    max_len = min(ax.shape[0], len(feature_pool))\n    for i in range(max_len):\n        axes = ax[i]\n        y,x = df[[target_feature,feature_pool[i]]].to_numpy().T\n        axes.scatter(x,y, marker = '.')\n        axes.set_ylabel(target_feature)\n        axes.set_xlabel(feature_pool[i])\n        axes.set_title(f'{target_feature} vs \\n {feature_pool[i]}')\n        \n    fig.show()\n\nfeature_pool = ['MST', 'Global CMP22 (vent/cor) [W/m^2]',\n       'Direct sNIP [W/m^2]', 'Azimuth Angle [degrees]',\n       'Tower Dry Bulb Temp [deg C]', 'Tower Wet Bulb Temp [deg C]',\n       'Tower Dew Point Temp [deg C]', 'Tower RH [%]',\n       'Peak Wind Speed @ 6ft [m/s]', 'Avg Wind Direction @ 6ft [deg from N]',\n       'Station Pressure [mBar]', 'Precipitation (Accumulated) [mm]',\n       'Snow Depth [cm]', 'Moisture', 'Albedo (CMP11)']\nprint(len(feature_pool))\n\nrequired_df = train[(train['Total Cloud Cover [%]'] > 0) & (train['DATE (MM/DD)'] == '01/03')].reset_index()\n\nmake_plots(\n    required_df,\n    target_feature = 'Total Cloud Cover [%]',\n    feature_pool = feature_pool[0:8],\n    nrows = 2,\n    ncols = 4,\n    scale = 4\n)\n\nmake_plots(\n    required_df,\n    target_feature = 'Total Cloud Cover [%]',\n    feature_pool = feature_pool[8:],\n    nrows = 2,\n    ncols = 4,\n    scale = 4\n)","metadata":{}},{"cell_type":"markdown","source":"# Creating tensorflow datasets","metadata":{}},{"cell_type":"markdown","source":"## Sampling from within a day with non-zero Cloud Cover or within each day","metadata":{}},{"cell_type":"code","source":"# For Only non - Zero cloud cover\n# non_zero_indices = train['Total Cloud Cover [%]'] > 0\n# print(non_zero_indices.sum())\n# # for whole day\nnon_zero_indices = np.full([train.to_numpy().shape[0]], True)\nprint(non_zero_indices.sum())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.to_numpy().shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train_y_df = lagged_columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_X = train_x_df[non_zero_indices]\ndata_y = train_y_df[non_zero_indices]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.histplot(train[non_zero_indices]['Total Cloud Cover [%]'],bins = 100, kde = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_sequences_of_listed_days(days_list, data_df,train_x_df, train_y_df, window_size = 360, future_buffer = 30):\n        X_dataset_list = []\n        y_dataset_list = []\n        for day in days_list:\n            day_x_df = train_x_df.loc[data_df['DATE (MM/DD)'] == day].to_numpy()\n            day_y_df = train_y_df.loc[data_df['DATE (MM/DD)'] == day].to_numpy()\n            data_len = day_x_df.shape[0]\n            assert day_x_df.shape[0] == day_y_df.shape[0]\n            day_x_df = day_x_df[0 : data_len - future_buffer]\n#             day_y_df = day_y_df[window_size - 1:data_len - future_buffer]\n            day_y_df = day_y_df[window_size:]\n            X_dataset_list.append(get_dataset_of_sequences(day_x_df, window_size = window_size))\n            y_dataset_list.append(get_dataset_of_sequences(day_y_df, window_size = future_buffer))\n#             y_dataset_list.append(tf.data.Dataset.from_tensor_slices(day_y_df))\n            \n        \n        X_dataset = X_dataset_list[0]\n        y_dataset = y_dataset_list[0]\n        for dataset in X_dataset_list[1:]:\n            X_dataset = X_dataset.concatenate(dataset)\n        for dataset in y_dataset_list[1:]:\n            y_dataset = y_dataset.concatenate(dataset)\n        return X_dataset, y_dataset\n    \n\n    \ndef get_dataset_of_sequences(X, window_size = 360, stride = 1, shift = 1):\n    dataset = tf.data.Dataset.from_tensor_slices(X)\n    dataset = dataset.window(window_size,shift = shift, stride = stride,drop_remainder = True)\n    dataset = dataset.flat_map(lambda window : window.batch(window_size))\n    return dataset\n\ndef apply_dataset_optimizations(dataset,cache = False, batch_size = 32, shuffle = False, shuffle_size = 32):\n    if cache:\n        dataset = dataset.cache()\n    if shuffle:\n        dataset = dataset.shuffle(buffer_size=shuffle_size)\n    dataset = dataset.batch(batch_size)\n    dataset = dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n    return dataset","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gap = 2\nfuture_buffer = 30 / gap # 30 minutes because sampling every minute\nsequence_size = 360 / gap\nprint(future_buffer, sequence_size)\nfuture_buffer,sequence_size = int(future_buffer),int(sequence_size)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = data_X[::gap]\ny = data_y[::gap]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"assert len(X) == len(y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(X))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"days_list = train.iloc[:,0].unique()\ndays_list = sorted(days_list)\nprint(days_list[0:10])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_datasets(X,y,days_list,train,window_size,future_buffer):\n    dataset_val = tf.data.Dataset.zip(\n        get_sequences_of_listed_days(\n            days_list[-17:], \n            train, \n            X, \n            y, \n            window_size = window_size, \n            future_buffer = future_buffer)\n    )\n    dataset_train = tf.data.Dataset.zip(\n        get_sequences_of_listed_days(\n            days_list[-18::-1][::-1], \n            train, \n            X, \n            y,  \n            window_size = window_size, \n            future_buffer = future_buffer)\n    )\n\n    print(dataset_val.as_numpy_iterator().next()[0].shape, dataset_val.as_numpy_iterator().next()[1].shape)\n    print(dataset_train.as_numpy_iterator().next()[0].shape, dataset_train.as_numpy_iterator().next()[1].shape)\n    return dataset_train, dataset_val","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_train, dataset_val = get_datasets(\n    X = X,\n    y = y,\n    days_list = days_list,\n    train = train,\n    window_size = sequence_size,\n    future_buffer = future_buffer\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(dataset_val.as_numpy_iterator().next()[0].shape, dataset_val.as_numpy_iterator().next()[1].shape)\nprint(dataset_train.as_numpy_iterator().next()[0].shape, dataset_train.as_numpy_iterator().next()[1].shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_val = apply_dataset_optimizations(\n    dataset_val,\n    batch_size = 32, \n    cache = True\n)\ndataset_train = apply_dataset_optimizations(\n    dataset_train,\n    batch_size = 32, \n    cache = True\n)\n\nprint(dataset_val.as_numpy_iterator().next()[0].shape, dataset_val.as_numpy_iterator().next()[1].shape)\nprint(dataset_train.as_numpy_iterator().next()[0].shape, dataset_train.as_numpy_iterator().next()[1].shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.isnan(np.concatenate([data[1] for data in dataset_val.as_numpy_iterator()])).shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = tf.keras.models.load_model('/kaggle/input/ccd-ai/keras/LSTM-series-B/5/LSTM_series_B_early_stopped.keras')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer='adam',\nloss=tf.keras.losses.MeanSquaredError(),\nmetrics=[\n    tf.keras.metrics.R2Score(), \n#     r2_score_per_class,\n    tf.keras.metrics.MeanAbsoluteError(),\n    tf.keras.metrics.MeanAbsolutePercentageError(),\n    tf.keras.metrics.RootMeanSquaredError(),\n])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.evaluate(dataset_val, return_dict = True), ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Saving Models to Kaggle Database","metadata":{}},{"cell_type":"markdown","source":"## Secret and Directory Initialization","metadata":{}},{"cell_type":"code","source":"dir_to_new_model = '/kaggle/working/models'\nimport os\nimport json\n\nfrom kaggle_secrets import UserSecretsClient\nsecrets = UserSecretsClient()\n\nos.environ['KAGGLE_USERNAME'] = secrets.get_secret(\"KAGGLE_USERNAME\")\nos.environ['KAGGLE_KEY'] = secrets.get_secret(\"KAGGLE_KEY\")\n\nos.makedirs('/kaggle/working/models', exist_ok = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Creating Kaggle Models","metadata":{}},{"cell_type":"code","source":"\n\nmodel_meta_data = {\n  \"ownerSlug\": \"ishansrivastava1308\",\n  \"title\": \"CloudCover AI\",\n  \"slug\": \"ccd-ai\",\n  \"subtitle\": \"\",\n  \"isPrivate\": False,\n  \"description\": \"# Model Summary\\n\\n# Model Characteristics\\n\\n# Data Overview\\n\\n# Evaluation Results\\n\",\n  \"publishTime\": \"\",\n  \"provenanceSources\": \"\"\n}\n\nwith open(os.path.join(dir_to_new_model,'model-metadata.json'), 'w') as f:\n    json.dump(model_meta_data, f)\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#  !kaggle models create --path /kaggle/working/models","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Creating Model instance","metadata":{}},{"cell_type":"code","source":"model_instance_meta_data = {\n  \"ownerSlug\": \"ishansrivastava1308\",\n  \"modelSlug\": \"ccd-ai\",\n  \"instanceSlug\": \"attention-seq-to-seq\",\n  \"framework\": \"keras\",\n  \"overview\": \"\",\n  \"usage\": \"# Model Format\\n\\n# Training Data\\n\\n# Model Inputs\\n\\n# Model Outputs\\n\\n# Model Usage\\n\\n# Fine-tuning\\n\\n# Changelog\\n\",\n  \"licenseName\": \"Apache 2.0\",\n  \"fineTunable\": True,\n  \"trainingData\": [],\n  \"modelInstanceType\": \"Unspecified\",\n  \"baseModelInstanceId\": 0,\n  \"externalBaseModelUrl\": \"\"\n}\n\nwith open(os.path.join('/kaggle/working/models','model-instance-metadata.json'), 'w') as f:\n    json.dump(model_instance_meta_data, f)\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!kaggle models instances create -p /kaggle/working/models --dir-mode tar","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Creating model versions","metadata":{}},{"cell_type":"code","source":"!kaggle models instances versions create ishansrivastava1308/ccd-ai/keras/attention-seq-to-seq -p /kaggle/working/models --dir-mode tar","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Metrics and Callbacks","metadata":{}},{"cell_type":"markdown","source":"## Callbacks","metadata":{}},{"cell_type":"code","source":"class LossAndErrorPrintingCallback(tf.keras.callbacks.Callback):\n    def on_epoch_end(self, epoch, logs=None):\n        if logs:\n            print()\n            val = {}\n            train = defaultdict(lambda: \"None\")\n            for k,v in logs.items():\n                if k.startswith('val_'):\n                    val[k[4:]] = v\n                else:\n                    train[k] = [v, \"None\"]\n            # print(val, train)\n\n            for k,v in val.items():\n                if train[k] != \"None\":\n                    train[k][1] = v\n                else:\n                    train[k] = [\"None\", v]\n\n            print(\"+\",\"-\"*42,\"+\",\"-\"*42,\"+\",\"-\"*42,\"+\",sep = \"\")\n            print(\"| {:<40} | {:<40} | {:<40} |\".format(\"Metrics\",\"Train\",\"Val\"))\n            print(\"+\",\"-\"*42,\"+\",\"-\"*42,\"+\",\"-\"*42,\"+\",sep = \"\")\n            for k,v in train.items():\n                print(\"| {:<40} | {:<40} | {:<40} |\".format(k, v[0], v[1]))\n            print(\"+\",\"-\"*128,\"+\",sep = \"\")\n            print()\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class SaveModelOnEpoch(tf.keras.callbacks.Callback):\n    def __init__(self, save_path,freq = 5,offset = 0):\n        super(SaveModelOnEpoch, self).__init__()\n        self.save_path = save_path\n        self.freq = freq\n        self.offset = offset\n\n    def on_epoch_end(self, epoch, logs=None):\n        if (epoch + 1) % self.freq == 0:  # Save every 5 epochs\n            self.model.save(self.save_path.format(epoch=self.offset+epoch+1))\n            print(f\"Model saved at epoch {self.offset+epoch+1}.\")\n        \nsave_callback = SaveModelOnEpoch('/kaggle/working/models/Seq_to_seq_LSTM_{epoch}.keras',offset = 0, freq = 2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class PlotPredictionsCallback(tf.keras.callbacks.Callback):\n    def __init__(self, x_val, y_val, start = 0, end = None):\n        super(PlotPredictionsCallback, self).__init__()\n        self.x_val = x_val\n        self.y_val = y_val.flatten()\n        self.start = start\n        self.end = end\n\n    def on_epoch_end(self, epoch, logs=None):\n        y_pred = self.model.predict(self.x_val)\n        \n        pd.DataFrame(np.column_stack([\n            y_pred.flatten()[start:end],\n            self.y_val[start:end]\n        ]), columns = [\"Predictions\", \"Ground Truth\"]).plot(figsize = (15,6), grid = True)\n        \n        ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom datetime import datetime\nmodel_dir  = '/kaggle/working/models'\nlog_dir = os.path.join(model_dir,\"logs/fit/\") + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\ntensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !cp -r /kaggle/input/ccd-ai/keras/LSTM-series-B/4/logs /kaggle/working/models","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_mean_absolute_error', patience=2, verbose=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%load_ext tensorboard\n%tensorboard --logdir {os.path.join(model_dir,\"logs/fit/\")}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!rm -rf /kaggle/working/logs","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# R2 Score Metric\nimport tensorflow as tf\nfrom sklearn.metrics import r2_score\n\ndef r2_score_per_class(y_true, y_pred):\n    print(y_true, y_pred)\n    r2_per_class = []\n    for i in range(y_true.shape[1]):  # Iterate over each class\n        r2 = r2_score(y_true[:, i], y_pred[:, i])\n        r2_per_class.append(r2)\n    return tf.convert_to_tensor(r2_per_class, dtype=tf.float32)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# LSTM Model\n","metadata":{}},{"cell_type":"code","source":"model = tf.keras.Sequential([\n    tf.keras.layers.Input((180,16)),\n    tf.keras.layers.Conv1D(1024,1),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Activation('relu'),\n    tf.keras.layers.Conv1D(512,1),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Activation('relu'),\n    tf.keras.layers.Conv1D(256,1),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Activation('relu'),\n    tf.keras.layers.Conv1D(256,1),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Activation('relu'),\n    tf.keras.layers.Conv1D(128,1),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Activation('linear'),\n    \n    tf.keras.layers.LSTM(256, return_sequences=True, ),\n    tf.keras.layers.LSTM(128, return_sequences=False,),\n    \n    tf.keras.layers.Dense(256, activation = 'relu'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dense(1, activation = 'linear')\n    \n])\n\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Multi-LSTM","metadata":{}},{"cell_type":"code","source":"n_past = 180\nn_future = 15\nn_features = 16\nn_output_features = 1\n\n\ninputs = tf.keras.layers.Input(shape=(n_past, n_features))\n\n# Inference Model\n# x = tf.keras.layers.Conv1D(1024,1)(inputs)\n# x = tf.keras.layers.BatchNormalization()(x)\n# x = tf.keras.layers.Activation('relu')(x)\n# x = tf.keras.layers.Conv1D(512,1)(x)\n# x = tf.keras.layers.BatchNormalization()(x)\n# x = tf.keras.layers.Activation('relu')(x)\nx = tf.keras.layers.Conv1D(512,1)(inputs)\nx = tf.keras.layers.BatchNormalization()(x)\nx = tf.keras.layers.Activation('relu')(x)\n# x = tf.keras.layers.Conv1D(256,1)(x)\n# x = tf.keras.layers.BatchNormalization()(x)\n# x = tf.keras.layers.Activation('relu')(x)\nx = tf.keras.layers.Conv1D(256,1)(x)\nx = tf.keras.layers.BatchNormalization()(x)\nx = tf.keras.layers.Activation('relu')(x)\nx = tf.keras.layers.Conv1D(128,1)(x)\nx = tf.keras.layers.BatchNormalization()(x)\nencoder_inputs = tf.keras.layers.Activation('linear')(x)\n\n\n\n# Sequence Encoder\nencoder_l1 = tf.keras.layers.LSTM(512,return_sequences = True, return_state=True,)\nencoder_outputs1 = encoder_l1(encoder_inputs)\nencoder_states1 = encoder_outputs1[1:]\n\n# concatenate = tf.keras.layers.Concatenate()([encoder_outputs1[0],inputs,encoder_inputs])\n# attention = tf.keras.layers.Attention()([concatenate, concatenate, concatenate])\n\nencoder_l2 = tf.keras.layers.LSTM(512, return_state=True,)\nencoder_outputs2 = encoder_l2(encoder_outputs1[0])\nencoder_states2 = encoder_outputs2[1:]\n#\ndecoder_inputs = tf.keras.layers.RepeatVector(n_future)(encoder_outputs2[0])\n#\ndecoder_l1 = tf.keras.layers.LSTM(512, return_sequences=True)(decoder_inputs, initial_state = encoder_states1)\ndecoder_l2 = tf.keras.layers.LSTM(512, return_sequences=True)(decoder_l1, initial_state = encoder_states2)\n\n# MLP to get outputs\n# decoder_outputs2 = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(n_features))(decoder_l2)\nx = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(256))(decoder_l2)\nx = tf.keras.layers.TimeDistributed(tf.keras.layers.BatchNormalization())(x)\nx = tf.keras.layers.TimeDistributed(tf.keras.layers.ReLU())(x)\ndecoder_outputs2 = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(n_output_features))(x)\n#\n\n\nmodel = tf.keras.models.Model(inputs,decoder_outputs2)\n#\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Seq to Seq with Attention","metadata":{}},{"cell_type":"code","source":"n_past = 180\nn_future = 15\nn_features = 16\nn_output_features = 1\ninputs = tf.keras.layers.Input(shape=(n_past, n_features))\n\ndef attention_layer(inputs):\n    inp = tf.keras.layers.Dense(128)(inputs)\n    attention = tf.keras.layers.MultiHeadAttention(num_heads=8, key_dim=64)(inp, inp, inp)\n    x = tf.keras.layers.Add()([inp, attention])\n    norm_add = tf.keras.layers.LayerNormalization()(x)\n\n    x = tf.keras.layers.Dense(128)(norm_add)\n    x = tf.keras.layers.ReLU()(x)\n    x = tf.keras.layers.Dense(128)(x)\n    x = tf.keras.layers.Add()([norm_add, x])\n    x = tf.keras.layers.LayerNormalization()(x)\n    return x\n\ndef make_model():\n    inference_model = tf.keras.models.Sequential([\n        tf.keras.layers.Conv1D(128,1),\n        tf.keras.layers.BatchNormalization(),\n        tf.keras.layers.Activation('relu'),\n        tf.keras.layers.Conv1D(64,1),\n        tf.keras.layers.BatchNormalization(),\n        tf.keras.layers.Activation('relu'),\n        tf.keras.layers.Conv1D(32,1),\n        tf.keras.layers.BatchNormalization(),\n        tf.keras.layers.Activation('linear'),\n    ], name = 'Inference_model')\n\n#     encoder_inputs = inference_model(inputs)\n    encoder_l1 = tf.keras.layers.LSTM(128,return_sequences = True, return_state=True)\n    enc_seq1, enc_h1, enc_c1 = encoder_l1(inputs)\n\n    # attention = tf.keras.layers.MultiHeadAttention(num_heads=8, key_dim=64)\n    # attention_output = attentioreturn_staten(*[enc_seq1, enc_seq1, enc_seq1])\n    # We get a attention score for each of the layers\n\n\n    attention = attention_layer(enc_seq1)\n    attention = attention_layer(attention)\n    attention = attention_layer(attention)\n    context_vector = tf.keras.layers.Multiply()([attention,enc_seq1])\n\n\n    decoder_hidden_states = [enc_h1, enc_c1]\n\n    outputs = []\n    for i in range(n_future):\n        hidden_rep = tf.keras.layers.RepeatVector(180)(decoder_hidden_states[0])\n        context_rep = tf.keras.layers.RepeatVector(180)(decoder_hidden_states[0])\n        concatenation = tf.keras.layers.Concatenate(axis = -1)([context_vector, encoder_inputs, hidden_rep, context_rep])\n        self_attention = tf.keras.layers.Conv1D(128,1)(concatenation)\n        self_attention = tf.keras.layers.BatchNormalization()(self_attention)\n        self_attention = tf.keras.layers.Activation('relu')(self_attention)\n#         self_attention = tf.keras.layers.Conv1D(64,1)(self_attention)\n#         self_attention = tf.keras.layers.BatchNormalization()(self_attention)\n#         self_attention = tf.keras.layers.Activation('relu')(self_attention)\n#         self_attention = tf.keras.layers.Conv1D(32,1)(self_attention)\n#         self_attention = tf.keras.layers.BatchNormalization()(self_attention)\n#         self_attention = tf.keras.layers.Activation('relu')(self_attention)\n        self_attention = tf.keras.layers.Conv1D(1,1)(self_attention)\n        self_attention = tf.keras.layers.BatchNormalization()(self_attention)\n        self_attention = tf.keras.layers.Activation('linear')(self_attention)\n        self_attention = tf.keras.layers.Flatten()(self_attention)\n        cell_outputs, decoder_hidden_states = tf.keras.layers.LSTMCell(128)(self_attention,decoder_hidden_states)\n        cell_outputs = tf.keras.layers.Reshape((1,128))(cell_outputs)\n        outputs.append(cell_outputs)\n\n        # Decoding\n\n    concatenate_outputs = tf.keras.layers.Concatenate(axis = -2)(outputs)\n    \n    x = tf.keras.layers.Conv1D(256,1)(concatenate_outputs)\n    x = tf.keras.layers.ReLU()(x)\n    x = tf.keras.layers.Conv1D(256,1)(concatenate_outputs)\n    x = tf.keras.layers.ReLU()(x)\n    x = tf.keras.layers.Conv1D(1,1)(x)\n\n    model = tf.keras.Model(inputs, x)\n    return model\n\nmodel = make_model()\nmodel.summary()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Encoder Decoder with attention","metadata":{}},{"cell_type":"code","source":"n_past = 180\nn_future = 15\nn_features = 16\nn_output_features = 1\n\n\ndef attention_layer(inputs):\n    inp = tf.keras.layers.Dense(64)(inputs)\n    attention = tf.keras.layers.MultiHeadAttention(num_heads=8, key_dim=64)(inp, inp, inp)\n    x = tf.keras.layers.Add()([inp, attention])\n    norm_add = tf.keras.layers.LayerNormalization()(x)\n\n    x = tf.keras.layers.Dense(64)(norm_add)\n    x = tf.keras.layers.ReLU()(x)\n    x = tf.keras.layers.Dense(64)(x)\n    x = tf.keras.layers.Add()([norm_add, x])\n    x = tf.keras.layers.LayerNormalization()(x)\n    return x\n\ndef attention_layer_decoder(inputs, key, value):\n    inp = tf.keras.layers.Dense(64)(inputs)\n    attention = tf.keras.layers.MultiHeadAttention(num_heads=8, key_dim=64)(inp, key, value)\n    x = tf.keras.layers.Add()([inp, attention])\n    norm_add = tf.keras.layers.LayerNormalization()(x)\n\n    x = tf.keras.layers.Dense(64)(norm_add)\n    x = tf.keras.layers.ReLU()(x)\n    x = tf.keras.layers.Dense(64)(x)\n    x = tf.keras.layers.Add()([norm_add, x])\n    x = tf.keras.layers.LayerNormalization()(x)\n    return x\n\ndef get_attention_sequence(inputs):\n    encoder_l1 = tf.keras.layers.LSTM(64,return_sequences = True, return_state=True,)\n    encoder_outputs1 = encoder_l1(inputs)\n    attention_1 = attention_layer(encoder_outputs1[0])\n    return attention_1, encoder_outputs1\n\ndef get_decoder_attention(inputs, key, value, hidden_states):\n    encoder_l1 = tf.keras.layers.LSTM(64,return_sequences = True, return_state=True)\n    encoder_outputs1 = encoder_l1(inputs, initial_state = hidden_states)\n    attention_1 = attention_layer_decoder(encoder_outputs1[0], key, value)\n    return attention_1, encoder_outputs1\n\n\ninputs = tf.keras.layers.Input(shape=(n_past, n_features))\n\n# Sequence Encoder\nattention_1, encoder_hidden_1 = get_attention_sequence(inputs)\n\nattention_2, encoder_hidden_2 = get_attention_sequence(attention_1)\n\nattention_3, encoder_hidden_3 = get_attention_sequence(attention_1)\n\n# Compressor\n\ncompressor_outputs = tf.keras.layers.LSTM(1024, return_state = True)(attention_3)\n\ndecoder_inputs = tf.keras.layers.RepeatVector(n_future)(compressor_outputs[0])\n\ndecoder_attention_1, _ = get_decoder_attention(decoder_inputs, attention_3, attention_3, encoder_hidden_3[1:])\n\ndecoder_attention_2, _ = get_decoder_attention(decoder_attention_1, attention_2, attention_2, encoder_hidden_2[1:])\n\ndecoder_attention_1, _ = get_decoder_attention(decoder_attention_2, attention_1, attention_1, encoder_hidden_3[1:])\n\nx = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(256))(decoder_attention_1)\nx = tf.keras.layers.TimeDistributed(tf.keras.layers.BatchNormalization())(x)\nx = tf.keras.layers.TimeDistributed(tf.keras.layers.ReLU())(x)\ndecoder_outputs2 = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(n_output_features))(x)\n#\n\n\nmodel = tf.keras.models.Model(inputs,decoder_outputs2)\n#\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Training","metadata":{}},{"cell_type":"code","source":"model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_val = np.concatenate([data[0] for data in dataset_train])\ny_val = np.concatenate([data[1] for data in dataset_train])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(x_val.shape, y_val.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(\n    x = x_val,\n    y = y_val,\n    validation_data = dataset_val,\n    initial_epoch = 3,\n    epochs = 20,\n    callbacks = [\n        LossAndErrorPrintingCallback(), \n#         PlotPredictionsCallback(x_val[::15],y_val[::15])\n        early_stopping, \n        save_callback, \n        tensorboard_callback\n    ],\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('/kaggle/working/models/Attention_LSTM_session_1.keras')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!kaggle models instances versions create ishansrivastava1308/ccd-ai/keras/LSTM-series-B -p /kaggle/working/models --dir-mode tar","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = tf.keras.models.load_model('/kaggle/working/models/Min_25_predictor_15.keras', compile = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Plotting and Evalutation","metadata":{}},{"cell_type":"code","source":"# fig,ax = plt.subplots(figsize = (15,5))\n# ax.plot(np.concatenate([batch1x[2,:,-1]]))\n\ndef plot_forecast(x,y,idx):\n    batch1x = x[idx:idx+15]\n    batch1y = y[idx:idx+15]\n    pred = model.predict(batch1x)\n    print(pred)\n\n    pred_df = pd.DataFrame(np.full((195,3),np.nan), columns = [\"Historical\",\"Preds\",\"Actual\"])\n    pred_df.loc[180:,[\"Preds\",\"Actual\"]] = np.column_stack([scalery.inverse_transform(pred[:]),scalery.inverse_transform(batch1y[:])])\n    pred_df.loc[:179,[\"Historical\"]] = scalery.inverse_transform(batch1x[0,:,-1].reshape(-1,1)),\n\n    pred_df.plot(figsize = (16,5))\n\n# plt.legend(['Train', 'Val', 'Predictions'], loc='lower right')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# fig,ax = plt.subplots(figsize = (15,5))\n# ax.plot(np.concatenate([batch1x[2,:,-1]]))\nx_val,y_true = dataset_val.as_numpy_iterator().next()\ndef plotter(x,y_true,y_pred):\n    pred_df = pd.DataFrame(np.full((195,3),np.nan), columns = [\"Historical\",\"Preds\",\"Actual\"])\n    pred_df.loc[180:,[\"Preds\",\"Actual\"]] = np.column_stack([scalery.inverse_transform(y_pred.reshape(-1)),scalery.inverse_transform(y_true)])\n    pred_df.loc[:179,[\"Historical\"]] = scalery.inverse_transform(x[:,-1].reshape(-1,1)),\n\n    pred_df.plot(figsize = (16,5))\n\ndef plot_decoder_forecast(x,y):\n    pred = model.predict(x.reshape(1,180,16))\n    print(pred.shape)\n    # shape = (batchsize, 15, 1)\n    \n\n# plt.legend(['Train', 'Val', 'Predictions'], loc='lower right')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_val","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_true = np.concatenate([data[0] for data in dataset_val])\ny_true = np.concatenate([data[1] for data in dataset_val])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"series_predictions = model.predict(x_true[::15])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"r2 = tf.keras.metrics.R2Score()\nr2.update_state(series_predictions.reshape(-1,1),y_true[::15].reshape(-1,1))\nr2.result()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"series_predictions.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nclass ComparisonPlotter:\n    def __init__(self):\n        pass\n    def plot_dataframe(self,start = 0, end = 0):\n        self.df.loc[start:end].plot(figsize = (16,6), grid = True)\n        start,end = 500,1700\n        \n    def set_df_from_columns(\n        columns_list\n        columns = None\n    ):\n        self._df = pd.DataFrame(np.column_stack(columns_list), columns = columns) \n        \n\n        ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plotter = ComparisonPlotter()\nplotter.set_df_from_columns(\n    [scalery.inverse_transform(series_predictions.reshape(-1,1)),\n    scalery.inverse_transform(y_true[::15].reshape(-1,1))],\n    columns = [\"Predictions\", \"True\"]\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import IPython\nfrom IPython.display import display\nfrom ipywidgets import interact, IntSlider, fixed, FloatSlider, IntRangeSlider, interactive,interactive_output, HBox, VBox, Box, Layout\n\nstart                     = IntSlider(description = 'Start'.ljust(15) + ':',  min = 1,max = plotter._df.shape[0], step = 1, value = 0)\nend                       = IntSlider(description = 'End'.ljust(15) + ':',  min = 1,max = plotter._df.shape[0],step = 1, value = plotter._df.shape[0])\n\nargs = {\n    'start' : start ,\n    'end'  : end ,\n}\n\nplot_widget = interactive_output(\n    plotter.plot_dataframe,\n    args\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nstart,end = 0,None\npd.DataFrame(np.column_stack([\n    series_predictions[start:end][:,1],\n    y_true[start:end][:,1]\n])).plot(figsize = (15,6), grid = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"idx = 260\nplot_decoder_forecast(x_val[idx], y_true[idx])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scalery.inverse_transform(model.predict(X_train[0]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = model.predict(dataset_val)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_val = np.concatenate([data[1] for data in dataset_val])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.DataFrame(np.column_stack([scalery.inverse_transform(predictions), scalery.inverse_transform(y_val)]), columns = ['Preds', 'True'])[500:1000].plot(figsize = (15,5))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}